
@misc{noauthor_fittss_2017,
	title = {Fitts's law},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Fitts%27s_law&oldid=808217211},
	abstract = {Fitts's law (often cited as Fitts' law) is a predictive model of human movement primarily used in human–computer interaction and ergonomics. This scientific law predicts that the time required to rapidly move to a target area is a function of the ratio between the distance to the target and the width of the target. Fitts's law is used to model the act of pointing, either by physically touching an object with a hand or finger, or virtually, by pointing to an object on a computer monitor using a pointing device.
Fitts's law has been shown to apply under a variety of conditions; with many different limbs (hands, feet, the lower lip, head-mounted sights, eye gaze), manipulanda (input devices), physical environments (including underwater), and user populations (young, old, special educational needs, and drugged participants).},
	language = {en},
	urldate = {2017-11-25TZ},
	journal = {Wikipedia},
	month = nov,
	year = {2017},
	note = {Page Version ID: 808217211}
}

@misc{noauthor_contribute_2017,
	title = {Contribute to awesome-{SLAM}-list development by creating an account on {GitHub}},
	url = {https://github.com/OpenSLAM/awesome-SLAM-list},
	urldate = {2017-11-25TZ},
	publisher = {OpenSLAM},
	month = nov,
	year = {2017},
	note = {original-date: 2016-12-19T16:26:02Z}
}

@misc{yan_contribute_2017,
	title = {Contribute to {ORB}-{SLAM}-{Android} development by creating an account on {GitHub}},
	url = {https://github.com/castoryan/ORB-SLAM-Android},
	urldate = {2017-11-25TZ},
	author = {Yan, Qinrui},
	month = nov,
	year = {2017},
	note = {original-date: 2016-03-30T23:11:59Z}
}

@misc{aivijay_lsd_slam_noros_2017,
	title = {lsd\_slam\_noros: {LSD}-{SLAM}},
	copyright = {GPL-3.0},
	shorttitle = {lsd\_slam\_noros},
	url = {https://github.com/aivijay/lsd_slam_noros},
	urldate = {2017-11-25TZ},
	author = {aivijay},
	month = nov,
	year = {2017},
	note = {original-date: 2015-05-10T01:41:56Z}
}

@misc{noauthor_simultaneous_2017,
	title = {Simultaneous localization and mapping},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Simultaneous_localization_and_mapping&oldid=807615182},
	abstract = {In robotic mapping and navigation, simultaneous localization and mapping (SLAM) is the computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it. While this initially appears to be a chicken-and-egg problem there are several algorithms known for solving it, at least approximately, in tractable time for certain environments. Popular approximate solution methods include the particle filter and extended Kalman filter.
SLAM algorithms are tailored to the available resources, hence not aimed at perfection, but at operational compliance. Published approaches are employed in self-driving cars, unmanned aerial vehicles, autonomous underwater vehicles, planetary rovers, newly emerging domestic robots and even inside the human body.},
	language = {en},
	urldate = {2017-11-25TZ},
	journal = {Wikipedia},
	month = oct,
	year = {2017},
	note = {Page Version ID: 807615182}
}

@misc{noauthor_vuforia_nodate,
	title = {Vuforia {\textbar} {Augmented} {Reality}},
	url = {https://www.vuforia.com/},
	urldate = {2017-11-25TZ}
}

@misc{noauthor_arcore_nodate,
	title = {{ARCore} - {Google} {Developer} {\textbar} {ARCore}},
	url = {https://developers.google.com/ar/},
	abstract = {Build apps that understand space and motion in high fidelity.},
	urldate = {2017-11-25TZ},
	journal = {Google Developers}
}

@article{kolb_brain_2011,
	title = {Brain {Plasticity} and {Behaviour} in the {Developing} {Brain}},
	volume = {20},
	issn = {1719-8429},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3222570/},
	abstract = {Objective:
To review general principles of brain development, identify basic principles of brain plasticity, and discuss factors that influence brain development and plasticity.

Method:
A literature review of relevant English-language manuscripts on brain development and plasticity was conducted.

Results:
Brain development progresses through a series of stages beginning with neurogenesis and progressing to neural migration, maturation, synaptogenesis, pruning, and myelin formation. Eight basic principles of brain plasticity are identified. Evidence that brain development and function is influenced by different environmental events such as sensory stimuli, psychoactive drugs, gonadal hormones, parental-child relationships, peer relationships, early stress, intestinal flora, and diet.

Conclusions:
The development of the brain reflects more than the simple unfolding of a genetic blueprint but rather reflects a complex dance of genetic and experiential factors that shape the emerging brain. Understanding the dance provides insight into both normal and abnormal development.},
	number = {4},
	urldate = {2017-11-25TZ},
	journal = {Journal of the Canadian Academy of Child and Adolescent Psychiatry},
	author = {Kolb, Bryan and Gibb, Robbin},
	month = nov,
	year = {2011},
	pmid = {22114608},
	pmcid = {PMC3222570},
	pages = {265--276}
}

@misc{noauthor_out_2017,
	title = {Out {Run}},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Out_Run&oldid=809908534},
	abstract = {Out Run (アウトラン, Auto Ran) is an arcade game released by Sega in 1986. It was designed by Yu Suzuki and developed by Sega AM2. The game was a critical and commercial success, becoming one of the best-selling video games of its time. It is notable for its pioneering hardware and graphics, and innovative features such as a selectable soundtrack with music composed by Hiroshi Kawaguchi, along with nonlinear gameplay.},
	language = {en},
	urldate = {2017-11-25TZ},
	journal = {Wikipedia},
	month = nov,
	year = {2017},
	note = {Page Version ID: 809908534}
}

@misc{noauthor_frequency_2017,
	title = {Frequency modulation},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Frequency_modulation&oldid=808647064},
	abstract = {In telecommunications and signal processing, frequency modulation (FM) is the encoding of information in a carrier wave by varying the instantaneous frequency of the wave. This contrasts with amplitude modulation, in which the amplitude of the carrier wave varies, while the frequency remains constant.
In analog frequency modulation, such as FM radio broadcasting of an audio signal representing voice or music, the instantaneous frequency deviation, the difference between the frequency of the carrier and its center frequency, is proportional to the modulating signal.
Digital data can be encoded and transmitted via FM by shifting the carrier's frequency among a predefined set of frequencies representing digits - for example one frequency can represent a binary 1 and a second can represent binary 0. This modulation technique is known as frequency-shift keying (FSK). FSK is widely used in modems and fax modems, and can also be used to send Morse code. Radioteletype also uses FSK.
Frequency modulation is widely used for FM radio broadcasting. It is also used in telemetry, radar, seismic prospecting, and monitoring newborns for seizures via EEG, two-way radio systems, music synthesis, magnetic tape-recording systems and some video-transmission systems. In radio transmission, an advantage of frequency modulation is that it has a larger signal-to-noise ratio and therefore rejects radio frequency interference better than an equal power amplitude modulation (AM) signal. For this reason, most music is broadcast over FM radio.
Frequency modulation has a close relationship with phase modulation; phase modulation is often used as an intermediate step to achieve frequency modulation. Mathematically both of these are considered a special case of quadrature amplitude modulation (QAM).},
	language = {en},
	urldate = {2017-11-25TZ},
	journal = {Wikipedia},
	month = nov,
	year = {2017},
	note = {Page Version ID: 808647064}
}

@article{niehorster_accuracy_2017,
	title = {The Accuracy and Precision of Position and Orientation Tracking in the {HTC} Vive Virtual Reality System for Scientific Research},
	volume = {8},
	issn = {2041-6695},
	url = {https://doi.org/10.1177/2041669517708205},
	doi = {10.1177/2041669517708205},
	abstract = {The advent of inexpensive consumer virtual reality equipment enables many more researchers to study perception with naturally moving observers. One such system, the {HTC} Vive, offers a large field-of-view, high-resolution head mounted display together with a room-scale tracking system for less than a thousand U.S. dollars. If the position and orientation tracking of this system is of sufficient accuracy and precision, it could be suitable for much research that is currently done with far more expensive systems. Here we present a quantitative test of the {HTC} Vive’s position and orientation tracking as well as its end-to-end system latency. We report that while the precision of the Vive’s tracking measurements is high and its system latency (22 ms) is low, its position and orientation measurements are provided in a coordinate system that is tilted with respect to the physical ground plane. Because large changes in offset were found whenever tracking was briefly lost, it cannot be corrected for with a one-time calibration procedure. We conclude that the varying offset between the virtual and the physical tracking space makes the {HTC} Vive at present unsuitable for scientific experiments that require accurate visual stimulation of self-motion through a virtual world. It may however be suited for other experiments that do not have this requirement.},
	pages = {2041669517708205},
	number = {3},
	journaltitle = {i-Perception},
	shortjournal = {i-Perception},
	author = {Niehorster, Diederick C. and Li, Li and Lappe, Markus},
	urldate = {2018-03-26},
	date = {2017-06-01},
	langid = {english},
	file = {SAGE PDF Full Text:/Users/hrishioa/Zotero/storage/MEGSH3Q7/Niehorster et al. - 2017 - The Accuracy and Precision of Position and Orienta.pdf:application/pdf}
}

@article{kristjansson_designing_nodate,
	title = {Designing sensory-substitution devices: {Principles}, pitfalls and potential1},
	volume = {34},
	issn = {0922-6028},
	shorttitle = {Designing sensory-substitution devices},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5044782/},
	doi = {10.3233/RNN-160647},
	abstract = {An exciting possibility for compensating for loss of sensory function is to augment deficient senses by conveying missing information through an intact sense. Here we present an overview of techniques that have been developed for sensory substitution (SS) for the blind, through both touch and audition, with special emphasis on the importance of training for the use of such devices, while highlighting potential pitfalls in their design. One example of a pitfall is how conveying extra information about the environment risks sensory overload. Related to this, the limits of attentional capacity make it important to focus on key information and avoid redundancies. Also, differences in processing characteristics and bandwidth between sensory systems severely constrain the information that can be conveyed. Furthermore, perception is a continuous process and does not involve a snapshot of the environment. Design of sensory substitution devices therefore requires assessment of the nature of spatiotemporal continuity for the different senses. Basic psychophysical and neuroscientific research into representations of the environment and the most effective ways of conveying information should lead to better design of sensory substitution systems. Sensory substitution devices should emphasize usability, and should not interfere with other inter- or intramodal perceptual function. Devices should be task-focused since in many cases it may be impractical to convey too many aspects of the environment. Evidence for multisensory integration in the representation of the environment suggests that researchers should not limit themselves to a single modality in their design. Finally, we recommend active training on devices, especially since it allows for externalization, where proximal sensory stimulation is attributed to a distinct exterior object.},
	number = {5},
	urldate = {2017-11-25TZ},
	journal = {Restorative Neurology and Neuroscience},
	author = {Kristjánsson, Árni and Moldoveanu, Alin and Jóhannesson, Ómar I. and Balan, Oana and Spagnol, Simone and Valgeirsdóttir, Vigdís Vala and Unnthorsson, Rúnar},
	pmid = {27567755},
	pmcid = {PMC5044782},
	pages = {769--787},
	year = {2016}
}

@misc{hoefer_meet_nodate,
	title = {Meet {The} {Tacit} {Project}. {It}’s {Sonar} {For} {The} {Blind}.},
	url = {http://grathio.com/2011/08/meet-the-tacit-project-its-sonar-for-the-blind/},
	urldate = {2017-11-25TZ},
	journal = {Grathio},
	author = {Hoefer, Steve}
}

@inproceedings{akhter_smartphone-based_2011,
	title = {A {Smartphone}-based {Haptic} {Vision} {Substitution} system for the blind},
	doi = {10.1109/NEBC.2011.5778565},
	abstract = {Haptic Vision Substitution is a relatively new Human-Machine Interface (HMI) designed to help the blind to `see' through touch. This paper documents the implementation and design of a Smartphone-based vibrotactile system that uses Catadioptric stereo imaging to increase the spatial awareness of a visually impaired individual. The system computes a disparity map, where distance from an object is inversely proportional to the intensity, using Computer Vision techniques. This information is then compressed and sent to a microcontroller via Bluetooth to be actuated on an 8×8 matrix of shaftless coin vibration motors composing the vibrotactile interface. The interface is built into a wearable vest, where actuation occurs on the upper back region. The upper back was chosen as it is a relatively unused area of the body, providing minimal contraction, and has the somatosensory neuron resolution to accommodate an 8×8 vibrotactile array. This study also includes research on the effectiveness of the haptic transduction and methods of enhancing the tactile sensation to provide a more seamless user experience. It also builds the basis for a programmable tactile interface that would open the doors to a variety of applications for the blind.},
	booktitle = {2011 {IEEE} 37th {Annual} {Northeast} {Bioengineering} {Conference} ({NEBEC})},
	author = {Akhter, S. and Mirsalahuddin, J. and Marquina, F. B. and Islam, S. and Sareen, S.},
	month = apr,
	year = {2011},
	keywords = {Arrays, Bluetooth, Cameras, Computer Vision techniques, Haptic interfaces, Mirrors, Smartphone-based haptic vision substitution system, Smartphone-based vibrotactile system, Stereo vision, Vibrations, blind, brain-computer interfaces, catadioptric stereo imaging, coin vibration motors, disparity map, handicapped aids, haptic transduction, mechanoception, microcontroller, microcontrollers, neurophysiology, programmable tactile interface, somatosensory neuron resolution, tactile sensation, telemedicine, vibrotactile array, vibrotactile interface, vision, visually impaired individual, wearable vest},
	pages = {1--2}
}

@article{stronks_visual_2016,
	title = {Visual task performance in the blind with the {BrainPort} {V}100 {Vision} {Aid}},
	volume = {13},
	issn = {1743-4440},
	url = {https://doi.org/10.1080/17434440.2016.1237287},
	doi = {10.1080/17434440.2016.1237287},
	abstract = {Introduction: The BrainPort® V100 Vision Aid is a non-invasive assistive device for the blind based on sensory substitution. The device translates camera images into electrotactile stimuli delivered to the tongue. The BrainPort has recently received the CE mark and FDA approval and it is currently marketed to augment, rather than replace, the traditional assistive technologies such as the white cane or guide dog.Areas covered: In this work, we will review the functional studies performed to date with the BrainPort and we will highlight the critical factors that determine device performance, including the technology behind the BrainPort, the impediments to assessing device performance, and the impact of device training and rehabilitation.Expert commentary: The BrainPort enables blind people to perceive light, identify simple objects, recognize short words, localize simple objects, and detect motion and orientation of objects. To achieve this, proper rehabilitation and training regimes are crucial.},
	number = {10},
	urldate = {2017-11-25TZ},
	journal = {Expert Review of Medical Devices},
	author = {Stronks, H. Christiaan and Mitchell, Ellen B. and Nau, Amy C. and Barnes, Nick},
	month = oct,
	year = {2016},
	pmid = {27633972},
	keywords = {Sensory substitution, assistive technology, blindness, electrotactile stimulation, low vision, low-vision aid, psychophysics, rehabilitation, tongue display unit, ultra-low vision},
	pages = {919--931}
}

@article{nau_acquisition_2015,
	title = {Acquisition of {Visual} {Perception} in {Blind} {Adults} {Using} the {BrainPort} {Artificial} {Vision} {Device}},
	volume = {69},
	issn = {0272-9490},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4281706/},
	doi = {10.5014/ajot.2015.011809},
	abstract = {Intensive low vision rehabilitation resulted in some functional improvement in a sample of blind adults using the BrainPort artificial vision device., OBJECTIVE. We sought to determine whether intensive low vision rehabilitation would confer any functional improvement in a sample of blind adults using the BrainPort artificial vision device., METHOD. Eighteen adults ages 28–69 yr (n = 10 men and n = 8 women) who had light perception only or worse vision bilaterally spent up to 6 hr per day for 1 wk undergoing structured rehabilitation interventions. The functional outcomes of object identification and word recognition were tested at baseline and after rehabilitation training., RESULTS. At baseline, participants were unable to complete the two functional assessments. After participation in the 1-wk training protocol, participants were able to use the BrainPort device to complete the two tasks with moderate success., CONCLUSION. Without training, participants were not able to perform above chance level using the BrainPort device. As artificial vision technologies become available, occupational therapy practitioners can play a key role in clients’ success or failure in using these devices.},
	number = {1},
	urldate = {2017-11-25TZ},
	journal = {The American Journal of Occupational Therapy},
	author = {Nau, Amy C. and Pintar, Christine and Arnoldussen, Aimee and Fisher, Christopher},
	year = {2015},
	pmid = {25553750},
	pmcid = {PMC4281706},
	pages = {6901290010p1--6901290010p8}
}

@misc{noauthor_haptic_nodate,
	title = {The {Haptic} {Laser}: {Multi}-{Sensation} {Tactile} {Feedback} for {At}-a-{Distance} {Physical} {Space} {Perception} and {Interaction} ({F}.{Iannacci}, {E}.{Turnquist}) - {Google} {Search}},
	url = {https://www.google.com.sg/search?q=The+Haptic+Laser%3A+Multi-Sensation+Tactile+Feedback+for+At-a-Distance+Physical+Space+Perception+and+Interaction+(F.Iannacci%2C+E.Turnquist)&oq=The+Haptic+Laser%3A+Multi-Sensation+Tactile+Feedback+for+At-a-Distance+Physical+Space+Perception+and+Interaction+(F.Iannacci%2C+E.Turnquist)&aqs=chrome..69i57j69i64l2.467j0j1&sourceid=chrome&ie=UTF-8},
	urldate = {2017-11-25TZ}
}

@article{upson_tongue_2007,
	title = {Tongue {Vision}},
	volume = {44},
	issn = {0018-9235},
	doi = {10.1109/MSPEC.2007.273043},
	abstract = {Wicab, has developed the BrainPort, a device designed to help people with serious vision loss navigate by translating visual data from a camera into vibrations on the tongue. BrainPort can also be used to assist people with balance disorders by providing tactile feedback on changes in the way the head tilts. Unfortunately, the technology seems unlikely to provide enough clear benefits to counterbalance the cost and annoyance of wearing the device},
	number = {1},
	journal = {IEEE Spectrum},
	author = {Upson, S.},
	month = jan,
	year = {2007},
	keywords = {Biomedical engineering, BrainPort, Cameras, Chaos, Decoding, Electrodes, Feeds, Life estimation, Shape, Tongue, Voltage, Wicab, biomedical electrodes, handicapped aids, tactile feedback, tongue vibrations, vision loss, visual information translation},
	pages = {44--45}
}

@article{m._fitts_information_1992,
	title = {The Information Capacity of the Human Motor System in Controlling the Amplitude of Movement},
	volume = {121},
	doi = {10.1037/h0055392},
	abstract = {Reports of 3 experiments testing the hypothesis that the average duration of responses is directly proportional to the minimum average amount of information per response. The results show that the rate of performance is approximately constant over a wide range of movement amplitude and tolerance limits. This supports the thesis that "the performance capacity of the human motor system plus its associated visual and proprioceptive feedback mechanisms, when measured in information units, is relatively constant over a considerable range of task conditions." 25 references. ({PsycINFO} Database Record (c) 2006 {APA}, all rights reserved).},
	pages = {262--9},
	journaltitle = {Journal of experimental psychology. General},
	author = {M. Fitts, Paul},
	date = {1992-10-01}
}

@inproceedings{khambadkar_gist:_2013,
	address = {New York, NY, USA},
	series = {{UIST} '13},
	title = {{GIST}: {A} {Gestural} {Interface} for {Remote} {Nonvisual} {Spatial} {Perception}},
	isbn = {978-1-4503-2268-3},
	shorttitle = {{GIST}},
	url = {http://doi.acm.org/10.1145/2501988.2502047},
	doi = {10.1145/2501988.2502047},
	abstract = {Spatial perception is a challenging task for people who are blind due to the limited functionality and sensing range of hands. We present GIST, a wearable gestural interface that offers spatial perception functionality through the novel appropriation of the user's hands into versatile sensing rods. Using a wearable depth-sensing camera, GIST analyzes the visible physical space and allows blind users to access spatial information about this space using different hand gestures. By allowing blind users to directly explore the physical space using gestures, GIST allows for the closest mapping between augmented and physical reality, which facilitates spatial interaction. A user study with eight blind users evaluates GIST in its ability to help perform everyday tasks that rely on spatial perception, such as grabbing an object or interacting with a person. Results of our study may help develop new gesture based assistive applications.},
	urldate = {2017-11-25TZ},
	booktitle = {Proceedings of the 26th {Annual} {ACM} {Symposium} on {User} {Interface} {Software} and {Technology}},
	publisher = {ACM},
	author = {Khambadkar, Vinitha and Folmer, Eelke},
	year = {2013},
	keywords = {gestures, spatial perception, visual impairment},
	pages = {301--310}
}

@book{hawkins_intelligence:_2007,
	title = {On {Intelligence}: {How} a {New} {Understanding} of the {Brain} {Will} {Lead} to the {Creation} of {Truly} {Intelligent} {Machines}},
	isbn = {978-1-4299-0045-4},
	shorttitle = {On {Intelligence}},
	abstract = {From the inventor of the PalmPilot comes a new and compelling theory of intelligence, brain function, and the future of intelligent machinesJeff Hawkins, the man who created the PalmPilot, Treo smart phone, and other handheld devices, has reshaped our relationship to computers. Now he stands ready to revolutionize both neuroscience and computing in one stroke, with a new understanding of intelligence itself.Hawkins develops a powerful theory of how the human brain works, explaining why computers are not intelligent and how, based on this new theory, we can finally build intelligent machines.The brain is not a computer, but a memory system that stores experiences in a way that reflects the true structure of the world, remembering sequences of events and their nested relationships and making predictions based on those memories. It is this memory-prediction system that forms the basis of intelligence, perception, creativity, and even consciousness.In an engaging style that will captivate audiences from the merely curious to the professional scientist, Hawkins shows how a clear understanding of how the brain works will make it possible for us to build intelligent machines, in silicon, that will exceed our human ability in surprising ways.Written with acclaimed science writer Sandra Blakeslee, On Intelligence promises to completely transfigure the possibilities of the technology age. It is a landmark book in its scope and clarity.},
	language = {en},
	publisher = {Macmillan},
	author = {Hawkins, Jeff and Blakeslee, Sandra},
	month = apr,
	year = {2007},
	note = {Google-Books-ID: Qg2dmntfxmQC},
	keywords = {Computers / Intelligence (AI) \& Semantics, Science / Life Sciences / Neuroscience}
}

@misc{noauthor_brainport_nodate,
	title = {{BrainPort} {V}100 {Vision} {Aid}},
	url = {https://www.wicab.com},
	abstract = {BrainPort V100 is a vision aid for the profoundly blind, providing more mobility, independence, and confidence to users.},
	urldate = {2017-11-25TZ},
	journal = {BrainPort V100 Vision Aid},
	year = n.d
}

@misc{se_perception_nodate,
	title = {perception - {Why} is sensory substitution not that successful - {Cognitive} {Sciences} {Stack} {Exchange}},
	url = {https://cogsci.stackexchange.com/questions/9135/why-is-sensory-substitution-not-that-successful},
	urldate = {2017-11-25TZ},
	year = n.d,
	author = {SE, SE}
}

@misc{bach-y-rita_seeing_nodate,
	title = {Seeing with the {Brain}: {International} {Journal} of {Human}–{Computer} {Interaction}: {Vol} 15, {No} 2},
	url = {http://www.tandfonline.com/doi/abs/10.1207/S15327590IJHC1502_6?journalCode=hihc20},
	urldate = {2017-11-25TZ},
	year = {2003},
	author = {Bach-Y-Rita, Paul}
}

@article{white_vision_1969,
	title = {Vision {Substitution} by {Tactile} {Image} {Projection}},
	volume = {221},
	copyright = {1969 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/221963a0},
	doi = {10.1038/221963a0},
	abstract = {Vision Substitution by Tactile Image Projection},
	language = {En},
	number = {5184},
	urldate = {2017-11-25TZ},
	journal = {Nature},
	author = {White, Benjamin and Collins, Carter C. and Saunders, Frank A. and Scadden, Lawrence and Bach-Y-Rita, Paul},
	month = mar,
	year = {1969},
	pages = {963}
}

@misc{noauthor_can_nodate,
	title = {Can {You} {See} {With} {Your} {Tongue}? {\textbar} {DiscoverMagazine}.com},
	url = {http://discovermagazine.com/2003/jun/feattongue},
	urldate = {2017-11-25TZ}
}

@article{phillips_predictors_1993,
	title = {Predictors of {Assistive} {Technology} {Abandonment}},
	volume = {5.1},
	url = {https://cs.brynmawr.edu/Courses/cs380/fall2010/readings/Phillips1993.pdf},
	journal = {Assistive Technology},
	author = {Phillips, Betsy and Zhao, Hongxin},
	year = {1993}
}

@article{doidge_brain_2008,
	chapter = {News},
	title = {Brain {That} {Changes} {Itself}: into the abyss},
	issn = {0307-1235},
	shorttitle = {Brain {That} {Changes} {Itself}},
	url = {http://www.telegraph.co.uk/news/health/3355721/Brain-That-Changes-Itself-into-the-abyss.html},
	abstract = {Can a damaged brain change its own structure and learn to replace lost functions? Conventional neuroscience once said no, but pioneers in the field have achieved miraculous transformations. From his investigation of their work, Norman Doidge tells the story of the perpetually falling woman.},
	language = {en-GB},
	urldate = {2017-11-25TZ},
	author = {Doidge, by Norman},
	month = jul,
	year = {2008},
	keywords = {Health, News}
}

@inproceedings{mackenzie_extending_1992,
	location = {New York, {NY}, {USA}},
	title = {Extending Fitts' Law to Two-dimensional Tasks},
	isbn = {978-0-89791-513-7},
	url = {http://doi.acm.org/10.1145/142750.142794},
	doi = {10.1145/142750.142794},
	series = {{CHI} '92},
	abstract = {Fitts' law, a one-dimensional model of human movement, is commonly applied to two-dimensional target acquisition tasks on interactive computing systems. For rectangular targets, such as words, it is demonstrated that the model can break down and yield unrealistically low (even negative!) ratings for a task's index of difficulty ({ID}). The Shannon formulation is shown to partially correct this problem, since {ID} is always ≥ 0 bits. As well, two alternative interpretations “target width” are introduced that accommodate the two-dimensional nature of tasks. Results of an experiment are presented that show a significant improvement in the model's performance using the suggested changes.},
	pages = {219--226},
	booktitle = {Proceedings of the {SIGCHI} Conference on Human Factors in Computing Systems},
	publisher = {{ACM}},
	author = {{MacKenzie}, I. Scott and Buxton, William},
	urldate = {2018-03-26},
	date = {1992},
	keywords = {Fitts' law, human performance modeling, input devices, input tasks},
	file = {ACM Full Text PDF:/Users/hrishioa/Zotero/storage/ILASP59J/MacKenzie and Buxton - 1992 - Extending Fitts' Law to Two-dimensional Tasks.pdf:application/pdf}
}

@inproceedings{chun_evaluating_2004,
	title = {Evaluating haptics and 3D stereo displays using Fitts' law},
	doi = {10.1109/HAVE.2004.1391881},
	abstract = {This paper describes research performed at the {BioRobotics} lab at Stanford University on the development of a visio-haptic workstation for surgical simulation. This study focuses on the design tradeoffs and choices that must be made to successfully combine 3D stereo with haptic feedback to enable immersive interaction with simulated surgical environments. Specifically, the study concentrates on building a matrix for evaluating 3D stereo haptic workstations. This research attempts to make quantitative comparisons by using Fitts' Law and positioning test. This paper demonstrates that these methods are applicable to the evaluation of visio-haptic workstations and suggests directions for future research.},
	eventtitle = {Proceedings. Second International Conference on Creating, Connecting and Collaborating through Computing},
	pages = {53--58},
	booktitle = {Proceedings. Second International Conference on Creating, Connecting and Collaborating through Computing},
	author = {Chun, Kwonsoo and Verplank, B. and Barbagli, F. and Salisbury, K.},
	date = {2004-10},
	keywords = {3D stereo displays, {BioRobotics} lab, Computational modeling, Computer displays, Computer science, Computer simulation, digital simulation, Equations, Fitts law, haptic feedback, haptic interfaces, Haptic interfaces, haptics evaluation, medical computing, simulated surgical environment, Stanford University, surgery, Surgery, surgical simulation, Testing, Three dimensional displays, three-dimensional displays, visio-haptic workstation, Workstations},
	file = {IEEE Xplore Full Text PDF:/Users/hrishioa/Zotero/storage/X8USG48L/Chun et al. - 2004 - Evaluating haptics and 3D stereo displays using Fi.pdf:application/pdf}
}
